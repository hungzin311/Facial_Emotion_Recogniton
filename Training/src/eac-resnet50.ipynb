{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8250896,"sourceType":"datasetVersion","datasetId":4895652},{"sourceId":40741,"sourceType":"modelInstanceVersion","modelInstanceId":34299},{"sourceId":41135,"sourceType":"modelInstanceVersion","modelInstanceId":34613}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport csv\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nimport argparse\nimport pickle\nimport wandb\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nimport torchvision.models as models\nimport torch.utils.data as data\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-26T02:36:47.886280Z","iopub.execute_input":"2024-05-26T02:36:47.887290Z","iopub.status.idle":"2024-05-26T02:36:56.859379Z","shell.execute_reply.started":"2024-05-26T02:36:47.887192Z","shell.execute_reply":"2024-05-26T02:36:56.858615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Args:\n  def __init__(self):\n    self.raf_path = '/kaggle/input/raf-basic/raf-basic'\n    self.resnet50_path = '../model/resnet50_ft_weight.pkl'\n    self.label_path = 'list_patition_label.txt'\n    self.workers = 2\n    self.batch_size = 64\n    self.w = 7\n    self.h = 7\n    self.gpu = 0\n    self.lam = 5.0\n    self.epochs = 40\n\nargs = Args()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model**","metadata":{"execution":{"iopub.status.busy":"2024-05-08T09:18:56.716449Z","iopub.execute_input":"2024-05-08T09:18:56.716877Z","iopub.status.idle":"2024-05-08T09:18:56.723519Z","shell.execute_reply.started":"2024-05-08T09:18:56.716844Z","shell.execute_reply":"2024-05-08T09:18:56.722306Z"}}},{"cell_type":"code","source":"\n\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=8631, include_top=True):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.include_top = include_top\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n\n        if not self.include_top:\n            return x\n\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:36:56.861214Z","iopub.execute_input":"2024-05-26T02:36:56.861645Z","iopub.status.idle":"2024-05-26T02:36:56.889453Z","shell.execute_reply.started":"2024-05-26T02:36:56.861620Z","shell.execute_reply":"2024-05-26T02:36:56.888517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfrom torch.autograd import Variable\n\n\n\nclass Model(nn.Module):\n\n    def __init__(self, pretrained=True, num_classes=7):\n        super(Model, self).__init__()\n        resnet50 = ResNet(Bottleneck, [3, 4, 6, 3])\n        with open('/kaggle/input/resnet50/pytorch/resnet50_ft_weight.pkl/1/resnet50_ft_weight.pkl', 'rb') as f:\n            obj = f.read()\n        weights = {key: torch.from_numpy(arr) for key, arr in pickle.loads(obj, encoding='latin1').items()}\n        resnet50.load_state_dict(weights)\n\n        self.features = nn.Sequential(*list(resnet50.children())[:-2])\n        self.features2 = nn.Sequential(*list(resnet50.children())[-2:-1])\n        self.fc = nn.Linear(2048, 7)\n\n\n    def forward(self, x):\n        x = self.features(x)\n        #### 1, 2048, 7, 7\n        feature = self.features2(x)\n        #### 1, 2048, 1, 1\n\n        feature = feature.view(feature.size(0), -1)\n        output = self.fc(feature)\n\n        params = list(self.parameters())\n        fc_weights = params[-2].data\n        fc_weights = fc_weights.view(1, 7, 2048, 1, 1)\n        fc_weights = Variable(fc_weights, requires_grad = False)\n\n        # attention\n        feat = x.unsqueeze(1) # N * 1 * C * H * W\n        hm = feat * fc_weights\n        hm = hm.sum(2) # N * self.num_labels * H * W\n\n        return output, hm","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:36:56.890519Z","iopub.execute_input":"2024-05-26T02:36:56.890803Z","iopub.status.idle":"2024-05-26T02:36:56.909979Z","shell.execute_reply.started":"2024-05-26T02:36:56.890780Z","shell.execute_reply":"2024-05-26T02:36:56.909142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:36:56.911120Z","iopub.execute_input":"2024-05-26T02:36:56.911430Z","iopub.status.idle":"2024-05-26T02:36:59.243531Z","shell.execute_reply.started":"2024-05-26T02:36:56.911400Z","shell.execute_reply":"2024-05-26T02:36:59.242587Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Utils**","metadata":{}},{"cell_type":"code","source":"\ndef add_g(image_array, mean=0.0, var=30):\n    std = var ** 0.5\n    image_add = image_array + np.random.normal(mean, std, image_array.shape)\n    image_add = np.clip(image_add, 0, 255).astype(np.uint8)\n    return image_add\n\ndef flip_image(image_array):\n    return cv2.flip(image_array, 1)\n\ndef setup_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n\ndef generate_flip_grid(w, h, device):\n    # used to flip attention maps\n    x_ = torch.arange(w).view(1, -1).expand(h, -1)\n    y_ = torch.arange(h).view(-1, 1).expand(-1, w)\n    grid = torch.stack([x_, y_], dim=0).float().to(device)\n    grid = grid.unsqueeze(0).expand(1, -1, -1, -1)\n    grid[:, 0, :, :] = 2 * grid[:, 0, :, :] / (w - 1) - 1\n    grid[:, 1, :, :] = 2 * grid[:, 1, :, :] / (h - 1) - 1\n    grid[:, 0, :, :] = -grid[:, 0, :, :]\n    return grid\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:36:59.246511Z","iopub.execute_input":"2024-05-26T02:36:59.247182Z","iopub.status.idle":"2024-05-26T02:36:59.257632Z","shell.execute_reply.started":"2024-05-26T02:36:59.247153Z","shell.execute_reply":"2024-05-26T02:36:59.256646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dataset**","metadata":{}},{"cell_type":"code","source":"class RafDataset(data.Dataset):\n    def __init__(self, args, phase, basic_aug=True, transform=None):\n        self.raf_path = args.raf_path\n        self.phase = phase\n        self.basic_aug = basic_aug\n        self.transform = transform\n        df = pd.read_csv(os.path.join(self.raf_path, 'EmoLabel', args.label_path), sep=' ', header=None)\n\n        name_c = 0\n        label_c = 1\n        if phase == 'train':\n            dataset = df[df[name_c].str.startswith('train')]\n        else:\n            df = pd.read_csv(os.path.join(self.raf_path, 'EmoLabel/list_patition_label.txt'), sep=' ', header=None)\n            dataset = df[df[name_c].str.startswith('test')]\n\n        self.label = dataset.iloc[:, label_c].values - 1\n        images_names = dataset.iloc[:, name_c].values\n        self.aug_func = [flip_image, add_g]\n        self.file_paths = []\n        self.clean = (args.label_path == 'list_patition_label.txt')\n\n        for f in images_names:\n            f = f.split(\".\")[0]\n            f += '_aligned.jpg'\n            file_name = os.path.join(self.raf_path, 'DATASET', f)\n            self.file_paths.append(file_name)\n\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        label = self.label[idx]\n        image = cv2.imread(self.file_paths[idx])\n\n        image = image[:, :, ::-1]\n\n\n        if not self.clean:\n            image1 = image\n            image1 = self.aug_func[0](image)\n            image1 = self.transform(image1)\n\n        if self.phase == 'train':\n            if self.basic_aug and random.uniform(0, 1) > 0.5:\n                image = self.aug_func[1](image)\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.clean:\n            image1 = transforms.RandomHorizontalFlip(p=1)(image)\n\n        return image, label, idx, image1","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:36:59.259294Z","iopub.execute_input":"2024-05-26T02:36:59.259691Z","iopub.status.idle":"2024-05-26T02:36:59.272972Z","shell.execute_reply.started":"2024-05-26T02:36:59.259667Z","shell.execute_reply":"2024-05-26T02:36:59.272038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loss**","metadata":{}},{"cell_type":"code","source":"from torch.autograd import Variable\n\ndef ACLoss(att_map1, att_map2, grid_l, output):\n    flip_grid_large = grid_l.expand(output.size(0), -1, -1, -1)\n    flip_grid_large = Variable(flip_grid_large, requires_grad = False)\n    flip_grid_large = flip_grid_large.permute(0, 2, 3, 1)\n    att_map2_flip = F.grid_sample(att_map2, flip_grid_large, mode = 'bilinear', padding_mode = 'border', align_corners=True)\n    flip_loss_l = F.mse_loss(att_map1, att_map2_flip)\n    return flip_loss_l\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:36:59.274145Z","iopub.execute_input":"2024-05-26T02:36:59.274490Z","iopub.status.idle":"2024-05-26T02:36:59.287752Z","shell.execute_reply.started":"2024-05-26T02:36:59.274456Z","shell.execute_reply":"2024-05-26T02:36:59.286889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = Model()\ndevice = torch.device(\"cuda:0\")\nmodel.to(device)\nsetup_seed(0)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:36:59.288915Z","iopub.execute_input":"2024-05-26T02:36:59.289219Z","iopub.status.idle":"2024-05-26T02:37:00.476090Z","shell.execute_reply.started":"2024-05-26T02:36:59.289184Z","shell.execute_reply":"2024-05-26T02:37:00.475204Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Main**","metadata":{}},{"cell_type":"code","source":"\n\ndef train(args, model, train_loader, optimizer, scheduler, device):\n    running_loss = 0.0\n    iter_cnt = 0\n    correct_sum = 0\n\n    model.to(device)\n    model.train()\n\n    total_loss = []\n    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(train_loader):\n        imgs1 = imgs1.to(device)\n        imgs2 = imgs2.to(device)\n        labels = labels.to(device)\n\n\n        criterion = nn.CrossEntropyLoss(reduction='none')\n\n\n\n        output, hm1 = model(imgs1)\n        output_flip, hm2 = model(imgs2)\n\n        grid_l = generate_flip_grid(args.w, args.h, device)\n\n\n        loss1 = nn.CrossEntropyLoss()(output, labels)\n        flip_loss_l = ACLoss(hm1, hm2, grid_l, output)\n\n\n        loss = loss1 + args.lam * flip_loss_l\n\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\n        iter_cnt += 1\n        _, predicts = torch.max(output, 1)\n        correct_num = torch.eq(predicts, labels).sum()\n        correct_sum += correct_num\n        running_loss += loss\n\n    scheduler.step()\n    running_loss = running_loss / iter_cnt\n    acc = correct_sum.float() / float(train_loader.dataset.__len__())\n    return acc, running_loss\n\n\n\ndef test(model, test_loader, device):\n    with torch.no_grad():\n        model.eval()\n\n        running_loss = 0.0\n        iter_cnt = 0\n        correct_sum = 0\n        data_num = 0\n\n\n        for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(test_loader):\n            imgs1 = imgs1.to(device)\n            labels = labels.to(device)\n\n\n            outputs, _ = model(imgs1)\n\n\n            loss = nn.CrossEntropyLoss()(outputs, labels)\n\n            iter_cnt += 1\n            _, predicts = torch.max(outputs, 1)\n\n            correct_num = torch.eq(predicts, labels).sum()\n            correct_sum += correct_num\n\n            running_loss += loss\n            data_num += outputs.size(0)\n\n        running_loss = running_loss / iter_cnt\n        test_acc = correct_sum.float() / float(data_num)\n    return test_acc, running_loss\n\ntrain_loss = []\ntest_loss = []\ntrain_acc = []\ntest_acc = [] \n\ndef main():\n\n    train_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(scale=(0.02, 0.25)) ])\n\n    eval_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])])\n\n\n\n    train_dataset = RafDataset(args, phase='train', transform=train_transforms)\n    test_dataset = RafDataset(args, phase='test', transform=eval_transforms)\n\n\n\n    train_loader = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=args.batch_size,\n                                               shuffle=True,\n                                               num_workers=args.workers,\n                                               pin_memory=True)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size,\n                                              shuffle=False,\n                                              num_workers=args.workers,\n                                              pin_memory=True)\n\n\n\n\n   \n\n    optimizer = torch.optim.Adam(model.parameters() , lr=0.0001, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n\n    wandb.login(key = '80fb920b9b9c938e38c91805ea14911702e078be')\n    wandb.init(project = 'Facial Emotion Recognition')\n\n   \n\n    for i in range(1, args.epochs + 1):\n        train_acc_epoch, train_loss_epoch = train(args, model, train_loader, optimizer, scheduler, device)\n        train_acc.append(train_acc_epoch)\n        train_loss.append(train_loss_epoch)\n        test_acc_epoch, test_loss_epoch = test(model, test_loader, device)\n        test_acc.append(test_acc_epoch)\n        test_loss.append(test_loss_epoch)\n        print(str(i)+'_'+str(train_acc_epoch) +str(test_acc_epoch)+'\\n')\n\n        wandb.log({\"Train loss\": train_loss_epoch, \"Test loss\": test_loss_epoch,\n                  \"Train_acc\": train_acc_epoch, \"Test acc\": test_acc_epoch})\n\n    \nif __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T02:37:00.477658Z","iopub.execute_input":"2024-05-26T02:37:00.478055Z","iopub.status.idle":"2024-05-26T05:24:51.516103Z","shell.execute_reply.started":"2024-05-26T02:37:00.478022Z","shell.execute_reply":"2024-05-26T05:24:51.514777Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-05-26T05:24:51.518091Z","iopub.execute_input":"2024-05-26T05:24:51.518508Z","iopub.status.idle":"2024-05-26T05:24:51.526214Z","shell.execute_reply.started":"2024-05-26T05:24:51.518463Z","shell.execute_reply":"2024-05-26T05:24:51.525337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(test_acc, 'test_acc_resnet50_noise01.txt.pt')\ntorch.save(test_loss, 'test_loss.pt')\ntorch.save(train_acc, 'train_acc.pt')\ntorch.save(train_loss, 'train_loss.pt')\n\ntrain_loss_values  =  [t.item() for t in train_loss]\ntest_loss_values = [y.item() for y in test_loss]\nplt.plot(train_loss_values,'b', label = 'Train loss')\nplt.plot(test_loss_values, 'r', label = 'Test_loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T05:24:51.527944Z","iopub.execute_input":"2024-05-26T05:24:51.529172Z","iopub.status.idle":"2024-05-26T05:24:52.003071Z","shell.execute_reply.started":"2024-05-26T05:24:51.529138Z","shell.execute_reply":"2024-05-26T05:24:52.002042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_values  =  [t.item() for t in train_acc]\ntest_loss_values = [y.item() for y in test_acc]\nplt.plot(train_loss_values,'b', label = 'Train acc')\nplt.plot(test_loss_values, 'r', label = 'Test_acc')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Acc\")\nplt.title(\"Accuracy\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T05:24:52.006124Z","iopub.execute_input":"2024-05-26T05:24:52.006403Z","iopub.status.idle":"2024-05-26T05:24:52.381413Z","shell.execute_reply.started":"2024-05-26T05:24:52.006378Z","shell.execute_reply":"2024-05-26T05:24:52.380327Z"},"trusted":true},"execution_count":null,"outputs":[]}]}